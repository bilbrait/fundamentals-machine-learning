{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a4a83ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import sklearn.datasets as data\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sb; sb.set_style( 'darkgrid' ) # use whitegrid if prefer a white background\n",
    "import pandas as pd\n",
    "\n",
    "from numpy.random import SeedSequence, default_rng\n",
    "rng = default_rng( SeedSequence().entropy )\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "#matplotlib.rcParams.update( { 'font.size': 18 } ) # Use this to setup your preferred font size for plotting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27c259ab",
   "metadata": {},
   "source": [
    "#### 1 - Use a Restricted Boltzmann Machine (RBM) to learn a neural representation of the image features. Then combine the neural model with another classifier and how it affects the accuracy. Compare the combination also to a singular model which has not been combined with the RBM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85e567db",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.ndimage import convolve\n",
    "\n",
    "from sklearn import datasets\n",
    "from sklearn.preprocessing import minmax_scale\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "def nudge_dataset(X, Y):\n",
    "    \"\"\"\n",
    "    This produces a dataset 5 times bigger than the original one,\n",
    "    by moving the 8x8 images in X around by 1px to left, right, down, up\n",
    "    \"\"\"\n",
    "    direction_vectors = [\n",
    "        [[0, 1, 0], [0, 0, 0], [0, 0, 0]],\n",
    "        [[0, 0, 0], [1, 0, 0], [0, 0, 0]],\n",
    "        [[0, 0, 0], [0, 0, 1], [0, 0, 0]],\n",
    "        [[0, 0, 0], [0, 0, 0], [0, 1, 0]],\n",
    "    ]\n",
    "\n",
    "    def shift(x, w):\n",
    "        return convolve(x.reshape((8, 8)), mode=\"constant\", weights=w).ravel()\n",
    "\n",
    "    X = np.concatenate(\n",
    "        [X] + [np.apply_along_axis(shift, 1, X, vector) for vector in direction_vectors]\n",
    "    )\n",
    "    Y = np.concatenate([Y for _ in range(5)], axis=0)\n",
    "    return X, Y\n",
    "\n",
    "\n",
    "X, y = datasets.load_digits(return_X_y=True)\n",
    "X = np.asarray(X, \"float32\")\n",
    "X, Y = nudge_dataset(X, y)\n",
    "X = minmax_scale(X, feature_range=(0, 1))  # 0-1 scaling\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split( X, Y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85b4c861",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here's some models to try with and without preprocessing\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import SGDClassifier, Perceptron\n",
    "from sklearn.linear_model import PassiveAggressiveClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import BernoulliRBM\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "logistic = LogisticRegression(solver=\"newton-cg\", tol=1)\n",
    "rbm = BernoulliRBM(random_state = rng.integers( 111 ), verbose=True)\n",
    "\n",
    "rbm_features_classifier = Pipeline(steps=[(\"rbm\", rbm), (\"logistic\", logistic)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e421f0b9",
   "metadata": {},
   "source": [
    "+ Change the number of RBM iterations and components, and learning rate.\n",
    "+ Experiment with different hyperparameters in the classifier model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9b4a35e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import clone\n",
    "\n",
    "# Hyper-parameters. These were set by cross-validation,\n",
    "# using a GridSearchCV. Here we are not performing cross-validation to\n",
    "# save time.\n",
    "rbm.learning_rate = 0.06 #\n",
    "rbm.n_iter = 10\n",
    "\n",
    "# More components tend to give better prediction performance, but larger\n",
    "# fitting time\n",
    "rbm.n_components = 100\n",
    "logistic.C = 6000\n",
    "\n",
    "# Training RBM-Logistic Pipeline\n",
    "rbm_features_classifier.fit(X_train, Y_train)\n",
    "\n",
    "# Training the Logistic regression classifier directly on the pixel\n",
    "raw_pixel_classifier = clone(logistic)\n",
    "raw_pixel_classifier.C = 100.0\n",
    "raw_pixel_classifier.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1faa0c19",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "Y_pred = rbm_features_classifier.predict(X_test)\n",
    "print(\n",
    "    \"Logistic regression using RBM features:\\n%s\\n\"\n",
    "    % (metrics.classification_report(Y_test, Y_pred))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26d6fabd",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred = raw_pixel_classifier.predict(X_test)\n",
    "print(\n",
    "    \"Logistic regression using raw pixel features:\\n%s\\n\"\n",
    "    % (metrics.classification_report(Y_test, Y_pred))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e9004f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(4.2, 4))\n",
    "for i, comp in enumerate(rbm.components_):\n",
    "    plt.subplot(10, 10, i + 1)\n",
    "    plt.imshow(comp.reshape((8, 8)), cmap=plt.cm.gray_r, interpolation=\"nearest\")\n",
    "    plt.xticks(())\n",
    "    plt.yticks(())\n",
    "plt.suptitle(\"100 components extracted by RBM\", fontsize=16)\n",
    "plt.subplots_adjust(0.08, 0.02, 0.92, 0.85, 0.08, 0.23)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47e03f21",
   "metadata": {},
   "source": [
    "#### 2 - Repeat the previous exercise but now with PCA. How does this compare to the RBM approach?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84c3bed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import SGDClassifier, Perceptron\n",
    "from sklearn.linear_model import PassiveAggressiveClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "\n",
    "def lower_bound(cv_results):\n",
    "    \"\"\"\n",
    "    Calculate the lower bound within 1 standard deviation\n",
    "    of the best `mean_test_scores`.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    cv_results : dict of numpy(masked) ndarrays\n",
    "        See attribute cv_results_ of `GridSearchCV`\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    float\n",
    "        Lower bound within 1 standard deviation of the\n",
    "        best `mean_test_score`.\n",
    "    \"\"\"\n",
    "    best_score_idx = np.argmax(cv_results[\"mean_test_score\"])\n",
    "\n",
    "    return (\n",
    "        cv_results[\"mean_test_score\"][best_score_idx]\n",
    "        - cv_results[\"std_test_score\"][best_score_idx]\n",
    "    )\n",
    "\n",
    "\n",
    "def best_low_complexity(cv_results):\n",
    "    \"\"\"\n",
    "    Balance model complexity with cross-validated score.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    cv_results : dict of numpy(masked) ndarrays\n",
    "        See attribute cv_results_ of `GridSearchCV`.\n",
    "\n",
    "    Return\n",
    "    ------\n",
    "    int\n",
    "        Index of a model that has the fewest PCA components\n",
    "        while has its test score within 1 standard deviation of the best\n",
    "        `mean_test_score`.\n",
    "    \"\"\"\n",
    "    threshold = lower_bound(cv_results)\n",
    "    candidate_idx = np.flatnonzero(cv_results[\"mean_test_score\"] >= threshold)\n",
    "    best_idx = candidate_idx[\n",
    "        cv_results[\"param_reduce_dim__n_components\"][candidate_idx].argmin()\n",
    "    ]\n",
    "    return best_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fffb6f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline(\n",
    "    [\n",
    "        (\"reduce_dim\", PCA(random_state=42)),\n",
    "        (\"classify\", SVC(random_state=42, C=0.01)),\n",
    "    ]\n",
    ")\n",
    "\n",
    "param_grid = {\"reduce_dim__n_components\": [6, 8, 10, 12, 14]}\n",
    "\n",
    "grid = GridSearchCV(\n",
    "    pipe,\n",
    "    cv=10,\n",
    "    n_jobs=1,\n",
    "    param_grid=param_grid,\n",
    "    scoring=\"accuracy\",\n",
    "    refit=best_low_complexity,\n",
    ")\n",
    "X, y = datasets.load_digits(return_X_y=True)\n",
    "grid.fit(X, y)\n",
    "\n",
    "n_components = grid.cv_results_[\"param_reduce_dim__n_components\"]\n",
    "test_scores = grid.cv_results_[\"mean_test_score\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a81a5be4",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.bar(n_components, test_scores, width=1.3, color=\"b\")\n",
    "\n",
    "lower = lower_bound(grid.cv_results_)\n",
    "plt.axhline(np.max(test_scores), linestyle=\"--\", color=\"y\", label=\"Best score\")\n",
    "plt.axhline(lower, linestyle=\"--\", color=\".5\", label=\"Best score - 1 std\")\n",
    "\n",
    "plt.title(\"Balance model complexity and cross-validated score\")\n",
    "plt.xlabel(\"Number of PCA components used\")\n",
    "plt.ylabel(\"Digit classification accuracy\")\n",
    "plt.xticks(n_components.tolist())\n",
    "plt.ylim((0, 1.0))\n",
    "plt.legend(loc=\"upper left\")\n",
    "\n",
    "best_index_ = grid.best_index_\n",
    "\n",
    "print(\"The best_index_ is %d\" % best_index_)\n",
    "print(\"The n_components selected is %d\" % n_components[best_index_])\n",
    "print(\n",
    "    \"The corresponding accuracy score is %.2f\"\n",
    "    % grid.cv_results_[\"mean_test_score\"][best_index_]\n",
    ")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
